{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "58ba1915fced4e72",
      "metadata": {
        "collapsed": false,
        "id": "58ba1915fced4e72"
      },
      "source": [
        "# Run FunSearch on Bin Packing\n",
        "Five steps:\n",
        "1. Implement 'LLM' interface.\n",
        "2. Implement a 'SandBox' interface.\n",
        "3. Prepare a 'specification'.\n",
        "4. Prepare a dataset.\n",
        "5. Start FunSearch."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a2d02b8e9c3ba67",
      "metadata": {
        "collapsed": false,
        "id": "6a2d02b8e9c3ba67"
      },
      "source": [
        "## Preparation: download the project file from github. And update system path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22453e8153e0934c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22453e8153e0934c",
        "outputId": "ebabc949-b10d-467c-c955-513b45c277ca"
      },
      "outputs": [],
      "source": [
        "\n",
        "import sys\n",
        "\n",
        "sys.path.append('/ai_tps_funsearch_project/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k9JMHbfh8g3Q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "k9JMHbfh8g3Q",
        "outputId": "deba468b-b28a-4929-df10-e6d686ba7f9f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import sys, os\n",
        "\n",
        "dataset = {}\n",
        "def prepare_dataset(filename):\n",
        "  # print(type(filename))\n",
        "  with open(filename, \"r\") as f:\n",
        "      lines = f.readlines()\n",
        "\n",
        "  # 解析节点坐标数据\n",
        "  node_coords = {}\n",
        "  found_node_section = False\n",
        "  for line in lines:\n",
        "      if found_node_section:\n",
        "          if line.strip() == \"EOF\":\n",
        "              break\n",
        "          node_id, x, y = map(float, line.strip().split()) if filename == 'ali535.tsp' or 'bayg29.tsp'  else map(int, line.strip().split())\n",
        "          node_coords[node_id] = (x, y)\n",
        "      elif line.startswith(\"DISPLAY_DATA_SECTION\"):\n",
        "          found_node_section = True\n",
        "\n",
        "  # 绘制节点图\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  for node_id, (x, y) in node_coords.items():\n",
        "      plt.plot(x, y, 'bo')\n",
        "      plt.text(x, y, str(node_id), fontsize=8, ha='right')\n",
        "  plt.title('TSP Node Map')\n",
        "  plt.xlabel('X Coordinate')\n",
        "  plt.ylabel('Y Coordinate')\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "  dataset[filename] = node_coords\n",
        "  # print(node_coords)\n",
        "\n",
        "filepath = './data/bayg29.tsp'\n",
        "prepare_dataset(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MaoOurHtU_o2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaoOurHtU_o2",
        "outputId": "ab59d91f-d6fa-43fa-dd56-500d1254aea1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def coordinates_to_distance_matrix(coordinates):\n",
        "    num_cities = len(coordinates)\n",
        "    # 创建一个空的距离矩阵\n",
        "    distance_matrix = np.zeros((num_cities, num_cities))\n",
        "    # 获取城市的列表，并确保顺序一致\n",
        "    city_ids = sorted(coordinates.keys())\n",
        "\n",
        "    # 计算每对城市之间的欧式距离\n",
        "    for i in range(num_cities):\n",
        "        for j in range(i + 1, num_cities):\n",
        "            coord1 = coordinates[city_ids[i]]\n",
        "            coord2 = coordinates[city_ids[j]]\n",
        "            # 计算两点之间的欧式距离\n",
        "            distance = np.sqrt((coord1[0] - coord2[0])**2 + (coord1[1] - coord2[1])**2)\n",
        "            distance_matrix[i][j] = distance_matrix[j][i] = distance\n",
        "\n",
        "    return distance_matrix\n",
        "# print(dataset)\n",
        "\n",
        "input = {}\n",
        "for i in dataset.keys():\n",
        "    distance_matrix = coordinates_to_distance_matrix(dataset[i])\n",
        "    input[i] = distance_matrix\n",
        "print(input.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "484ece09",
      "metadata": {},
      "source": [
        "# LLM part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1999e45c9a568b08",
      "metadata": {
        "id": "1999e45c9a568b08"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import json\n",
        "import multiprocessing\n",
        "from typing import Collection, Any\n",
        "import http.client\n",
        "from implementation import sampler\n",
        "\n",
        "\n",
        "def _trim_preface_of_body(sample: str) -> str:\n",
        "    \"\"\"Trim the redundant descriptions/symbols/'def' declaration before the function body.\n",
        "    Please see my comments in sampler.LLM (in sampler.py).\n",
        "    Since the LLM used in this file is not a pure code completion LLM, this trim function is required.\n",
        "\n",
        "    -Example sample (function & description generated by LLM):\n",
        "    -------------------------------------\n",
        "    This is the optimized function ...\n",
        "    def priority_v2(...) -> ...:\n",
        "        return ...\n",
        "    This function aims to ...\n",
        "    -------------------------------------\n",
        "    -This function removes the description above the function's signature, and the function's signature.\n",
        "    -The indent of the code is preserved.\n",
        "    -Return of this function:\n",
        "    -------------------------------------\n",
        "        return ...\n",
        "    This function aims to ...\n",
        "    -------------------------------------\n",
        "    \"\"\"\n",
        "    lines = sample.splitlines()\n",
        "    func_body_lineno = 0\n",
        "    find_def_declaration = False\n",
        "    for lineno, line in enumerate(lines):\n",
        "        # find the first 'def' statement in the given code\n",
        "        if line[:3] == 'def':\n",
        "            func_body_lineno = lineno\n",
        "            find_def_declaration = True\n",
        "            break\n",
        "    if find_def_declaration:\n",
        "        code = ''\n",
        "        for line in lines[func_body_lineno + 1:]:\n",
        "            code += line + '\\n'\n",
        "        return code\n",
        "    return sample\n",
        "\n",
        "\n",
        "class LLMAPI(sampler.LLM):\n",
        "    \"\"\"Language model that predicts continuation of provided source code.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, samples_per_prompt: int, trim=True):\n",
        "        super().__init__(samples_per_prompt)\n",
        "        additional_prompt = ('Complete a different and more complex Python function. '\n",
        "                             'Be creative and you can insert multiple if-else and for-loop in the code logic.'\n",
        "                             'Only output the Python code, no descriptions.')\n",
        "        self._additional_prompt = additional_prompt\n",
        "        self._trim = trim\n",
        "\n",
        "    def draw_samples(self, prompt: str) -> Collection[str]:\n",
        "        \"\"\"Returns multiple predicted continuations of `prompt`.\"\"\"\n",
        "        return [self._draw_sample(prompt) for _ in range(self._samples_per_prompt)]\n",
        "\n",
        "    def _draw_sample(self, content: str) -> str:\n",
        "        prompt = '\\n'.join([content, self._additional_prompt])\n",
        "        while True:\n",
        "            try:\n",
        "                conn = http.client.HTTPSConnection(\"api.bltcy.ai\")\n",
        "                payload = json.dumps({\n",
        "                    \"max_tokens\": 1000,\n",
        "                    \"model\": \"gpt-4o\",\n",
        "                    \"messages\": [\n",
        "                        {\n",
        "                            \"role\": \"user\",\n",
        "                            \"content\": prompt\n",
        "                        }\n",
        "                    ]\n",
        "                })\n",
        "                headers = {\n",
        "                    'Authorization': 'Bearer sk-RwjJjBq7VVTFvhv9352929B353Bb41D68d2f0959EcEe3b6f',\n",
        "                    'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',\n",
        "                    'Content-Type': 'application/json'\n",
        "                }\n",
        "                conn.request(\"POST\", \"/v1/chat/completions\", payload, headers)\n",
        "                res = conn.getresponse()\n",
        "                data = res.read().decode(\"utf-8\")\n",
        "                data = json.loads(data)\n",
        "                response = data['choices'][0]['message']['content']\n",
        "                # trim function\n",
        "                if self._trim:\n",
        "                    response = _trim_preface_of_body(response)\n",
        "                return response\n",
        "            except Exception:\n",
        "                time.sleep(2)\n",
        "                continue"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d27817cdec2cedfc",
      "metadata": {
        "collapsed": false,
        "id": "d27817cdec2cedfc"
      },
      "source": [
        "## 2. Implement a 'SandBox' interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e3d88a87535b6b2",
      "metadata": {
        "id": "3e3d88a87535b6b2"
      },
      "outputs": [],
      "source": [
        "from implementation import evaluator\n",
        "from implementation import evaluator_accelerate\n",
        "\n",
        "\n",
        "class Sandbox(evaluator.Sandbox):\n",
        "    \"\"\"Sandbox for executing generated code. Implemented by RZ.\n",
        "\n",
        "    RZ: Sandbox returns the 'score' of the program and:\n",
        "    1) avoids the generated code to be harmful (accessing the internet, take up too much RAM).\n",
        "    2) stops the execution of the code in time (avoid endless loop).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, verbose=False, numba_accelerate=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            verbose         : Print evaluate information.\n",
        "            numba_accelerate: Use numba to accelerate the evaluation. It should be noted that not all numpy functions\n",
        "                              support numba acceleration, such as np.piecewise().\n",
        "        \"\"\"\n",
        "        self._verbose = verbose\n",
        "        self._numba_accelerate = numba_accelerate\n",
        "\n",
        "    def run(\n",
        "            self,\n",
        "            program: str,\n",
        "            function_to_run: str,  # RZ: refers to the name of the function to run (e.g., 'evaluate')\n",
        "            function_to_evolve: str,  # RZ: accelerate the code by decorating @numba.jit() on function_to_evolve.\n",
        "            inputs: Any,  # refers to the dataset\n",
        "            test_input: str,  # refers to the current instance\n",
        "            timeout_seconds: int,\n",
        "            **kwargs  # RZ: add this\n",
        "    ) -> tuple[Any, bool]:\n",
        "        \"\"\"Returns `function_to_run(test_input)` and whether execution succeeded.\n",
        "\n",
        "        RZ: If the generated code (generated by LLM) is executed successfully,\n",
        "        the output of this function is the score of a given program.\n",
        "        RZ: PLEASE NOTE THAT this SandBox is only designed for bin-packing problem.\n",
        "        \"\"\"\n",
        "        dataset = inputs[test_input]\n",
        "        try:\n",
        "            result_queue = multiprocessing.Queue()\n",
        "            process = multiprocessing.Process(\n",
        "                target=self._compile_and_run_function,\n",
        "                args=(program, function_to_run, function_to_evolve, dataset, self._numba_accelerate, result_queue)\n",
        "            )\n",
        "            process.start()\n",
        "            process.join(timeout=timeout_seconds)\n",
        "            if process.is_alive():\n",
        "                # if the process is not finished in time, we consider the program illegal\n",
        "                process.terminate()\n",
        "                process.join()\n",
        "                results = None, False\n",
        "            else:\n",
        "                if not result_queue.empty():\n",
        "                    results = result_queue.get_nowait()\n",
        "                else:\n",
        "                    results = None, False\n",
        "\n",
        "            return results\n",
        "        except:\n",
        "            return None, False\n",
        "\n",
        "    def _compile_and_run_function(self, program, function_to_run, function_to_evolve, dataset, numba_accelerate,\n",
        "                                  result_queue):\n",
        "        try:\n",
        "            # optimize the code (decorate function_to_run with @numba.jit())\n",
        "            if numba_accelerate:\n",
        "                program = evaluator_accelerate.add_numba_decorator(\n",
        "                    program=program,\n",
        "                    function_to_evolve=function_to_evolve\n",
        "                )\n",
        "            # compile the program, and maps the global func/var/class name to its address\n",
        "            all_globals_namespace = {}\n",
        "            # execute the program, map func/var/class to global namespace\n",
        "            exec(program, all_globals_namespace)\n",
        "            # get the pointer of 'function_to_run'\n",
        "            function_to_run = all_globals_namespace[function_to_run]\n",
        "            # return the execution results\n",
        "            results = function_to_run(dataset)\n",
        "            # the results must be int or float\n",
        "            if not isinstance(results, (int, float)):\n",
        "                result_queue.put((None, False))\n",
        "                return\n",
        "            result_queue.put((results, True))\n",
        "        except Exception:\n",
        "            # if raise any exception, we assume the execution failed\n",
        "            result_queue.put((None, False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec3a05827354f9ae",
      "metadata": {
        "collapsed": false,
        "id": "ec3a05827354f9ae"
      },
      "source": [
        "## 3. Prepare a 'specification'\n",
        "\n",
        "> 添加区块引用符号\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mL660zghZeZp",
      "metadata": {
        "id": "mL660zghZeZp"
      },
      "outputs": [],
      "source": [
        "specification = r'''\n",
        "import numpy as np\n",
        "\n",
        "def heuristic_tsp_solver(distances, priority_func):\n",
        "    \"\"\"Solve the TSP by selecting the next city based on a complex priority function.\"\"\"\n",
        "    num_cities = len(distances)\n",
        "    visited = [False] * num_cities\n",
        "    current_city = 0\n",
        "    visited[current_city] = True\n",
        "    tour = [current_city]\n",
        "    total_distance = 0\n",
        "\n",
        "    while len(tour) < num_cities:\n",
        "        # Get complex priorities for the next city based on the current city\n",
        "        priorities = priority_func(current_city, distances, visited)\n",
        "        # Mask priorities for visited cities to ensure they are not selected\n",
        "        masked_priorities = np.where(visited, np.inf, priorities)\n",
        "        # Select the next city with the highest priority (lowest cost)\n",
        "        next_city = np.argmin(masked_priorities)\n",
        "        visited[next_city] = True\n",
        "        tour.append(next_city)\n",
        "        total_distance += distances[current_city][next_city]\n",
        "        current_city = next_city\n",
        "\n",
        "    # Close the loop by returning to the starting city\n",
        "    total_distance += distances[current_city][tour[0]]\n",
        "    tour.append(tour[0])  # Optionally return to the starting city for visualization\n",
        "    return tour, total_distance\n",
        "\n",
        "@funsearch.run\n",
        "def evaluate(distance_matrix):\n",
        "    \"\"\"Evaluate heuristic function on a provided distance matrix for the TSP.\"\"\"\n",
        "    tour, total_distance = heuristic_tsp_solver(distance_matrix, priority)\n",
        "    # return {'tour': tour, 'total_distance': total_distance}\n",
        "    return -total_distance\n",
        "\n",
        "@funsearch.evolve\n",
        "def priority(current_city, distances, visited):\n",
        "    \"\"\"Calculate complex priorities for each city from the current city based on negative distance and other factors.\"\"\"\n",
        "    num_cities = len(distances)\n",
        "    priorities = np.full(num_cities, np.inf)\n",
        "    for city in range(num_cities):\n",
        "        if not visited[city]:\n",
        "            # Inverse of the distance (closer cities have higher priority)\n",
        "            distance_priority = -distances[current_city][city]\n",
        "            # Additional heuristic: dynamic cost based on some external condition or iteration dependent factor\n",
        "            dynamic_cost = 1 / (1 + np.sum(distances[city]))  # Example: inverse of sum of distances from this city\n",
        "            priorities[city] = distance_priority * dynamic_cost\n",
        "    return priorities\n",
        "\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e2f875d128a693a",
      "metadata": {
        "id": "2e2f875d128a693a"
      },
      "outputs": [],
      "source": [
        "specification = r'''\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# 全局变量，用于模拟信息素矩阵\n",
        "_pheromone = None\n",
        "_evaporation_rate = 0.5\n",
        "\n",
        "def hybrid_tsp_solver(distances, priority_func):\n",
        "    \"\"\"具有蚁群算法特性的TSP求解器，同时保持兼容性\"\"\"\n",
        "    num_cities = len(distances)\n",
        "\n",
        "    # 初始化全局信息素矩阵\n",
        "    global _pheromone\n",
        "    if _pheromone is None or len(_pheromone) != num_cities:\n",
        "        _pheromone = np.ones((num_cities, num_cities)) * 0.1\n",
        "\n",
        "    # 尝试多个起点（模拟多只蚂蚁）\n",
        "    best_tour = None\n",
        "    best_distance = float('inf')\n",
        "\n",
        "    # 模拟多只蚂蚁的搜索过程\n",
        "    num_ants = min(5, num_cities)\n",
        "    all_tours = []\n",
        "    all_distances = []\n",
        "\n",
        "    for ant in range(num_ants):\n",
        "        # 每只蚂蚁从城市0开始（为了一致性）\n",
        "        current_city = 0\n",
        "        visited = [False] * num_cities\n",
        "        visited[current_city] = True\n",
        "        tour = [current_city]\n",
        "        total_distance = 0\n",
        "\n",
        "        # 构建完整路径\n",
        "        while len(tour) < num_cities:\n",
        "            # 使用priority函数确定下一个城市\n",
        "            priorities = priority_func(current_city, distances, visited)\n",
        "            masked_priorities = np.where(visited, np.inf, priorities)\n",
        "            next_city = np.argmin(masked_priorities)\n",
        "\n",
        "            # 更新路径\n",
        "            visited[next_city] = True\n",
        "            tour.append(next_city)\n",
        "            total_distance += distances[current_city][next_city]\n",
        "            current_city = next_city\n",
        "\n",
        "        # 闭合回路\n",
        "        total_distance += distances[current_city][tour[0]]\n",
        "        tour.append(tour[0])\n",
        "\n",
        "        all_tours.append(tour)\n",
        "        all_distances.append(total_distance)\n",
        "\n",
        "        # 更新最佳路径\n",
        "        if total_distance < best_distance:\n",
        "            best_distance = total_distance\n",
        "            best_tour = tour\n",
        "\n",
        "    # 更新信息素矩阵（模拟蚁群算法的信息素更新）\n",
        "    _update_pheromone(all_tours, all_distances, distances)\n",
        "\n",
        "    return best_tour, best_distance\n",
        "\n",
        "def _update_pheromone(tours, distances, distance_matrix):\n",
        "    \"\"\"更新全局信息素矩阵\"\"\"\n",
        "    global _pheromone, _evaporation_rate\n",
        "\n",
        "    # 蒸发现有信息素\n",
        "    _pheromone = _pheromone * (1 - _evaporation_rate)\n",
        "\n",
        "    # 根据路径质量增加新的信息素\n",
        "    for i, tour in enumerate(tours):\n",
        "        # 信息素沉积量与路径长度成反比\n",
        "        deposit = 1.0 / max(0.1, distances[i])\n",
        "\n",
        "        # 更新路径上每一段的信息素\n",
        "        for j in range(len(tour) - 1):\n",
        "            city1, city2 = tour[j], tour[j + 1]\n",
        "            _pheromone[city1][city2] += deposit\n",
        "            _pheromone[city2][city1] += deposit  # 对称TSP\n",
        "\n",
        "@funsearch.run\n",
        "def evaluate(distance_matrix):\n",
        "    \"\"\"在指定距离矩阵上评估启发式函数\"\"\"\n",
        "    tour, total_distance = hybrid_tsp_solver(distance_matrix, priority)\n",
        "    return -total_distance  # 负号是因为FunSearch最大化分数\n",
        "\n",
        "@funsearch.evolve\n",
        "def priority(current_city, distances, visited):\n",
        "    \"\"\"\n",
        "    计算从当前城市到各城市的优先级值。\n",
        "    较低的值表示更高的优先级（将被更早选择）。\n",
        "\n",
        "    注意：必须保持此函数签名以保证与FunSearch框架兼容\n",
        "    \"\"\"\n",
        "    num_cities = len(distances)\n",
        "    priorities = np.full(num_cities, np.inf)\n",
        "\n",
        "    # 获取全局信息素矩阵\n",
        "    global _pheromone\n",
        "    if _pheromone is None or len(_pheromone) != num_cities:\n",
        "        pheromone = np.ones((num_cities, num_cities))\n",
        "    else:\n",
        "        pheromone = _pheromone\n",
        "\n",
        "    # 计算旅行进度\n",
        "    visited_count = sum(visited)\n",
        "    progress = visited_count / num_cities\n",
        "\n",
        "    for city in range(num_cities):\n",
        "        if not visited[city]:\n",
        "            # 基本距离因素\n",
        "            distance = distances[current_city][city]\n",
        "\n",
        "            # 连通性因素：考虑与其他未访问城市的连接质量\n",
        "            connectivity = 0\n",
        "            unvisited_count = 0\n",
        "            for next_city in range(num_cities):\n",
        "                if not visited[next_city] and next_city != city:\n",
        "                    connectivity += distances[city][next_city]\n",
        "                    unvisited_count += 1\n",
        "\n",
        "            avg_connectivity = connectivity / max(1, unvisited_count)\n",
        "\n",
        "            # 完成因素：考虑返回起点的成本\n",
        "            completion_factor = 0\n",
        "            if progress > 0.7:\n",
        "                start_city = 0  # 假设0是起始城市\n",
        "                completion_factor = distances[city][start_city]\n",
        "\n",
        "            # 信息素影响：获取从当前城市到考虑中城市的信息素值\n",
        "            pheromone_factor = pheromone[current_city][city]\n",
        "\n",
        "            # 自适应权重\n",
        "            w1 = 1.0  # 距离权重\n",
        "            w2 = 0.5 * (1 - progress)  # 连通性权重（旅行早期更重要）\n",
        "            w3 = 1.5 * progress  # 完成因素权重（旅行后期更重要）\n",
        "            w4 = 1.0  # 信息素权重\n",
        "\n",
        "            # 计算最终优先级（值越低越好）\n",
        "            heuristic_value = w1 * distance + w2 * avg_connectivity + w3 * completion_factor\n",
        "            pheromone_influence = 1.0 / (pheromone_factor + 0.01)  # 防止除以零\n",
        "\n",
        "            priorities[city] = heuristic_value * pheromone_influence\n",
        "\n",
        "    return priorities\n",
        "\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mR09g45Iv_oZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "mR09g45Iv_oZ",
        "outputId": "4d42743b-c534-47d9-f9c8-153f383ca221"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def heuristic_tsp_solver(distances, priority_func):\n",
        "    \"\"\"Solving the TSP Problem Using Enhanced Heuristics\"\"\"\n",
        "    num_cities = len(distances)\n",
        "    best_tour = None\n",
        "    best_distance = float('inf')\n",
        "\n",
        "    # Try several different starting points to find a better solution\n",
        "    start_cities = [0, random.randint(0, num_cities-1), num_cities//2]\n",
        "    for start_city in start_cities:\n",
        "        # Build the path from the starting city\n",
        "        visited = [False] * num_cities\n",
        "        current_city = start_city\n",
        "        visited[current_city] = True\n",
        "        tour = [current_city]\n",
        "        total_distance = 0\n",
        "\n",
        "        # Building a complete pathway\n",
        "        while len(tour) < num_cities:\n",
        "            # Determining the next city using the priority function\n",
        "            priorities = priority_func(current_city, distances, visited)\n",
        "            masked_priorities = np.where(visited, np.inf, priorities)\n",
        "            next_city = np.argmin(masked_priorities)\n",
        "\n",
        "            # Update Path\n",
        "            visited[next_city] = True\n",
        "            tour.append(next_city)\n",
        "            total_distance += distances[current_city][next_city]\n",
        "            current_city = next_city\n",
        "\n",
        "        # closed loop\n",
        "        total_distance += distances[current_city][tour[0]]\n",
        "\n",
        "        # Save the best path\n",
        "        if total_distance < best_distance:\n",
        "            best_distance = total_distance\n",
        "            best_tour = tour.copy()\n",
        "\n",
        "    # Simple 2-opt optimisation (if there is enough time)\n",
        "    best_tour, best_distance = two_opt_improvement(best_tour, distances, max_iterations=50)\n",
        "\n",
        "    return best_tour, best_distance\n",
        "\n",
        "def two_opt_improvement(tour, distances, max_iterations=100):\n",
        "    \"\"\"Optimising a given travel path using the 2-opt algorithm\"\"\"\n",
        "    n = len(tour)\n",
        "    best_tour = tour.copy()\n",
        "    best_distance = calculate_tour_distance(best_tour, distances)\n",
        "    improved = True\n",
        "    iterations = 0\n",
        "\n",
        "    while improved and iterations < max_iterations:\n",
        "        improved = False\n",
        "        iterations += 1\n",
        "\n",
        "        for i in range(1, n - 1):\n",
        "            for j in range(i + 1, n):\n",
        "                # Avoid invalid 2-opt operations (when j is the last city and i is the first city)\n",
        "                if i == 0 and j == n - 1:\n",
        "                    continue\n",
        "\n",
        "                # Creating a new path: reversing the part from i to j\n",
        "                new_tour = best_tour.copy()\n",
        "                new_tour[i:j+1] = reversed(best_tour[i:j+1])\n",
        "\n",
        "                # Calculate the length of the new path\n",
        "                new_distance = calculate_tour_distance(new_tour, distances)\n",
        "\n",
        "                # If the new path is better, accept it\n",
        "                if new_distance < best_distance:\n",
        "                    best_distance = new_distance\n",
        "                    best_tour = new_tour\n",
        "                    improved = True\n",
        "                    break\n",
        "\n",
        "            if improved:\n",
        "                break\n",
        "\n",
        "    return best_tour, best_distance\n",
        "\n",
        "def calculate_tour_distance(tour, distances):\n",
        "    \"\"\"Calculate the total distance of a given travelling path\"\"\"\n",
        "    total = 0\n",
        "    for i in range(len(tour) - 1):\n",
        "        total += distances[tour[i]][tour[i+1]]\n",
        "    # closed loop\n",
        "    total += distances[tour[-1]][tour[0]]\n",
        "    return total\n",
        "\n",
        "@funsearch.run\n",
        "def evaluate(distance_matrix):\n",
        "    \"\"\"Evaluate the TSP solution on a given distance matrix\"\"\"\n",
        "    tour, total_distance = heuristic_tsp_solver(distance_matrix, priority)\n",
        "    return -total_distance  # The negative sign is because FunSearch maximises the score\n",
        "\n",
        "@funsearch.evolve\n",
        "def priority(current_city, distances, visited):\n",
        "    \"\"\"\n",
        "    Calculates the priority value from the current city to each city.\n",
        "    Lower values indicate higher priority (will be selected earlier).\n",
        "    \"\"\"\n",
        "    num_cities = len(distances)\n",
        "    priorities = np.full(num_cities, np.inf)\n",
        "\n",
        "    # Calculating travel progress\n",
        "    visited_count = sum(visited)\n",
        "    progress = visited_count / num_cities\n",
        "\n",
        "    for city in range(num_cities):\n",
        "        if not visited[city]:\n",
        "            # Basic distance factor\n",
        "            distance = distances[current_city][city]\n",
        "\n",
        "            # Calculate the average distance from this city to all unvisited cities (connectivity)\n",
        "            connectivity = 0\n",
        "            unvisited_count = 0\n",
        "            for next_city in range(num_cities):\n",
        "                if not visited[next_city] and next_city != city:\n",
        "                    connectivity += distances[city][next_city]\n",
        "                    unvisited_count += 1\n",
        "\n",
        "            avg_connectivity = connectivity / max(1, unvisited_count)\n",
        "\n",
        "            # Consider the distance back to the starting point (more important later in the journey)\n",
        "            completion_factor = 0\n",
        "            if progress > 0.6:  # When more than 60 per cent of cities are visited\n",
        "                start_city = 0  # Assume 0 is the starting city\n",
        "                completion_factor = distances[city][start_city]\n",
        "\n",
        "            # Adjustment of weights according to travel progress\n",
        "            w1 = 1.0  # distance weighting\n",
        "            w2 = 0.8 * (1 - progress)  # Connectivity weighting (more important early in the trip)\n",
        "            w3 = 2.0 * progress  # Completion of path weights (more important later in the trip)\n",
        "\n",
        "            # Calculate priority (lower values indicate higher priority)\n",
        "            priorities[city] = w1 * distance + w2 * avg_connectivity + w3 * completion_factor\n",
        "\n",
        "    return priorities"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "391bfe61e1661e18",
      "metadata": {
        "collapsed": false,
        "id": "391bfe61e1661e18"
      },
      "source": [
        "## 4. Prepare a dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb66651fb2764ce9",
      "metadata": {
        "collapsed": false,
        "id": "cb66651fb2764ce9"
      },
      "source": [
        "## 5. Start FunSearch\n",
        "Please note that in jupyter notebook the following code will fail. This is because juypter does not support multiprocessing. Colab backend supports multiprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B-Hp6wsvfkdg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-Hp6wsvfkdg",
        "outputId": "1eddd3e7-b55c-4aa2-a502-1e860fac6e0a"
      },
      "outputs": [],
      "source": [
        "from implementation import funsearch\n",
        "from implementation import config\n",
        "\n",
        "# 移除 __main__ 限制\n",
        "class_config = config.ClassConfig(llm_class=LLMAPI, sandbox_class=Sandbox)\n",
        "config = config.Config(\n",
        "    samples_per_prompt=1,  # 每次提示生成的样本数\n",
        "    evaluate_timeout_seconds=30  # 增加超时时间到60秒\n",
        ")\n",
        "global_max_sample_num = 80  # 设置为无限循环，让算法持续搜索\n",
        "\n",
        "try:\n",
        "    funsearch.main(\n",
        "        specification=specification,  # TSP 规范代码\n",
        "        inputs=input,         # TSP 实例数据\n",
        "        config=config,\n",
        "        max_sample_nums=global_max_sample_num,\n",
        "        class_config=class_config,\n",
        "        log_dir='../logs/funsearch_llm_api'\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"FunSearch 运行出错: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
